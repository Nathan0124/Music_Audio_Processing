{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Homework 4 â€” (15 points)\n",
    "======\n",
    "### What to hand in\n",
    "You are to submit the following things for this homework:\n",
    "1. A Jupyter notebook containing all code and output (figures and audio). I should be able to evaluate the file to reproduce all output. \n",
    "1. Any other data that we tell you to save to a file (e.g. audio files).\n",
    "\n",
    "### How to hand it in\n",
    "To submit your lab:\n",
    "1. Compress all of the files specified into a .zip file. \n",
    "1. Name the file in the following manner, firstname_lastname_hw1.zip. For example, Bryan_Pardo_hw1.zip. \n",
    "1. Submit this .zip file via Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this code block 1st, to import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This line is a convenience to import most packages you'll need. You may need to import others (eg random and cmath)\n",
    "import IPython, numpy as np, scipy as sp, matplotlib.pyplot as plt, matplotlib, sklearn, librosa, cmath,math\n",
    "from IPython.display import Audio\n",
    " \n",
    "# This line makes sure your plots happen IN the webpage you're building, instead of in separate windows.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  STFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "from scipy.signal import hann\n",
    "\n",
    "def stft(signal, window_size, hop_size, window_type = 'hann'):\n",
    "    \"\"\"\n",
    "    Computes the short term fourier transform of a 1-D numpy array, where the array \n",
    "    is windowed into a set of subarrays, each of length window_size. The distance between\n",
    "    window centers (in samples) is given by hop_size. The type of window applied is\n",
    "    determined by window_type. This returns a 2-D numpy array where the ith column\n",
    "    is the FFT of the ith window. Each column contains an array of complex values.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    signal: The 1-d (complex or real) numpy array containing the signal\n",
    "    window_size: an integer scalar specifying the number of samples in a window\n",
    "    hop_size: an integer specifying the number of samples between the start of adjacent windows\n",
    "    window_type: a string specifying one of two \"hann\" or \"rectangular\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a 2D numpy array of complex numbers where the array column is the FFT of the ith window,\n",
    "    and the jth element in the ith column is the jth frequency of analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # figure out how many hops\n",
    "    length_to_cover_with_hops = len(signal) - window_size;\n",
    "    assert (length_to_cover_with_hops >= 0), \"window_size cannot be longer than the signal to be windowed\"\n",
    "    num_hops = 1 + length_to_cover_with_hops/hop_size;\n",
    "    \n",
    "    # make our window function\n",
    "    if (window_type == 'hann'):\n",
    "        window = sp.signal.hann(window_size, sym=False)\n",
    "    else:\n",
    "        window = np.ones(window_size)\n",
    "    \n",
    "    stft = [0]*num_hops\n",
    "    # fill the array with values \n",
    "    for hop in range(num_hops):\n",
    "        start = hop*hop_size\n",
    "        end = start + window_size\n",
    "        unwindowed_sound = signal[start:end]\n",
    "        windowed_sound =  unwindowed_sound * window\n",
    "        stft[hop]= fft(windowed_sound, window_size) \n",
    "    return np.array(stft).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISTFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import ifft\n",
    "\n",
    "def istft(X, hop_size):\n",
    "    \"\"\"\n",
    "    Takes a 2-D numpy array representing an STFT of some signal, where stft[i] \n",
    "    is the FFT of the ith window as input and stft[i,k] is the kth frequency of analysis.\n",
    "    Performs an inverse FFT on each window and then does overlap & add resynthesis to rebuild \n",
    "    the original signal the STFT was built from.\n",
    "    \n",
    "    Input Parameters\n",
    "    ----------------\n",
    "    X: a 2-D numpy array of complex numbers representing an STFT, where the ith \n",
    "    column is the FFT of the ith window, and the jth row is the jth frequency of analysis.\n",
    "        \n",
    "    hop_size: an integer specifying the number of samples between the start of adjacent windows.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a 1-d numpy array of (possibly complex) values representing the original signal used to make X\n",
    "    \"\"\"\n",
    "    \n",
    "    # make an empty signal of the appropriate length\n",
    "    window_size,num_hops = X.shape\n",
    "    signal_length = (num_hops-1)*hop_size + window_size \n",
    "    signal = np.zeros(signal_length,dtype='complex');\n",
    "    \n",
    "    #fill the signal\n",
    "    for n in range(num_hops):\n",
    "        start = n * hop_size\n",
    "        end = start + window_size\n",
    "        signal[start:end] = signal[start:end] + ifft(X[:,n])\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrogram (plotting function with zooming options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plt_spectrogram(X,win_length, hop_size, sample_rate, zoom_x=None, zoom_y=None,tick_labels='time-freq'):\n",
    "    \"\"\"\n",
    "    Plots the log magnitude spectrogram.\n",
    "    \n",
    "    Input Parameters:\n",
    "    ------------------\n",
    "    X: 2D complex numpy array containing the stft values. Rows correspond to frequency bins and columns to time frames.\n",
    "    win_length: the length of the analysis window\n",
    "    hop_size: the hop size between adjacent windows\n",
    "    sample_rate: sampling frequency\n",
    "    tick_labels: the type of x and y tick labels, there are two options:\n",
    "                 'time-freq': shows times (sec) on the x-axis and frequency (Hz) on the y-axis (default)\n",
    "                 'bin-frame': shows time frame number on the x-axis and frequency bin number on the y-axis\n",
    "                \n",
    "    zoom_x: 1 by 2 numpy array containing the range of values on the x-axis, e.g. zoom_t=np.array([x_start,x_end])\n",
    "    zoom_y: 1 by 2 numpy array containing the range of values on the y-axis, e.g. zoom_f=np.array([y_start,y_end])\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    ---------\n",
    "    times: 1D real numpy array containing time instances corresponding to stft frames\n",
    "    freqs: 1D real numpy array containing frequencies of analyasis up to Nyquist rate\n",
    "    2D plot of the magnitude spectrogram\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the size of stft\n",
    "    Nf,Nt=np.shape(X)\n",
    "    \n",
    "    # Compute the log magnitude spectrogram\n",
    "    X=20*np.log10(np.abs(X))\n",
    "    \n",
    "    # Extract the first half of the spectrum for each time frame\n",
    "    X=X[0:Nf/2]\n",
    "    Nf=np.shape(X)[0]\n",
    "        \n",
    "    # Generate time vector for plotting\n",
    "    times=(hop_size/float(sample_rate))*np.arange(Nt)\n",
    "    \n",
    "    # Generate frequency vector for plotting\n",
    "    freqs=(float(sample_rate)/win_length)*np.arange(Nf)\n",
    "    \n",
    "    # Generate time and frequency matrices for pcolormesh\n",
    "    times_matrix,freqs_matrix=np.meshgrid(times,freqs)\n",
    "    \n",
    "    # Plot the log magnitude spectrogram\n",
    "    plt.title('Log magnitude spectrogram')\n",
    "    if tick_labels == 'bin-frame':\n",
    "        plt.pcolormesh(X)\n",
    "        plt.xlabel('Time-frame Number')\n",
    "        plt.ylabel('Frequency-bin Number')\n",
    "    else:\n",
    "        plt.pcolormesh(times_matrix,freqs_matrix,X)\n",
    "        plt.xlabel('Time (sec)')\n",
    "        plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "        \n",
    "    # Zoom in on the plot if specified\n",
    "    if zoom_x is None and zoom_y is None:\n",
    "        plt.axis('tight')\n",
    "        \n",
    "    if zoom_x is not None:\n",
    "        plt.xlim(zoom_x)\n",
    "        \n",
    "    if zoom_y is not None:\n",
    "        plt.ylim(zoom_y)\n",
    "        \n",
    "    return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Frequency Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (1 point) Load *police_noisy.wav*. The audio contains a ringing noise somewhere. Calculate the STFT of the audio signal and the magnitude spectrogram respectively denoted by *X* and *V*. Keep in mind that the magnitude spectrogram includes only the first half of the spectrum for each time frame. Use the function *plt_spectrogram* provided above to plot the *log magnitude spectrogram* of the audio signal. Identify the region of the ringing noise. It should be a square of about 30 frequency bins by 30 time frames. Write down the frequency and time indices in your report. \n",
    "\n",
    "#### * Note: we need to find the coordinates of the noisy region in terms of frequency bin number and time frame number, not in Hz and seconds. You can use the tick_labels parameter to set the values on the x-axis and y-axis to the required units. Moreover, zoom-x and zoom-y parameters can be set to narrower ranges in order to give better estimates of the region boundaries. Be careful about the consistency of zoom-x and zoom-y units with tick-labels.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2. (1 points) Use the frequency and time indices you found in Question 1 to create a simple binary time-frequency mask to remove the region of the ringing noise. The binary mask, *M*, should be of the same size as the magnitude spectrogram *V*. Derive a full (two-sided) time-frequency mask, *M_full*, from *M* and apply it to the STFT of the noisy audio. Compute the denoised signal by tranforming the masked STFT, *X_masked*, back to time domain. Plot the magnitude spectrogram of the denoised audio and check that the region of the ringing noise has been removed. \n",
    "\n",
    "#### Explain why  you should apply the time-frequecy mask to the STFT and not to the magnitude spectrogram to extract the noise. Why do we need to derive a *full* time-frequency mask?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beat Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (1 point) We have provided an implementation of the autocorrelation function. Note that we normalize by the number of nonzero additons. Explain the effect this has (compared to the standard autocorrelation in numpy) and tell us why you think we did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def acorr(x):\n",
    "    \"\"\"\n",
    "    Takes a 1D numpy array and returns the autocorrelation. \n",
    "    \n",
    "    Input Parameter:\n",
    "    ----------------\n",
    "    x: 1D numpy array of length Lx\n",
    "    \n",
    "    Ouput Parameter:\n",
    "    ----------------\n",
    "    x_acorr: 1D numpy array of length x_len containing the values of the autocorrelation function of x\n",
    "    \n",
    "    Note: the actual length of autocorrelation function is (2*x_len)-1, but since this function is symmetric\n",
    "          we can cut off (x_len)-1 samples and return one side of length x_len without losing information. \n",
    "    \"\"\"\n",
    "    \n",
    "    x_len=np.size(x)\n",
    "    x_pad=np.concatenate([x,np.zeros(x_len-1)])\n",
    "    x_acorr=ifft(np.abs(fft(x_pad))**2).real\n",
    "    x_acorr=x_acorr[0:x_len]\n",
    "    \n",
    "    x_acorr=x_acorr/(np.arange(x_len)[::-1]+1)  # normalize by the number of nonzero additions\n",
    "            \n",
    "    return x_acorr\n",
    "\n",
    "# Test case: \n",
    "# Note: the numpy correlate function is not normalized so the results seem different. If you comment out the \n",
    "#       normalization line above the outputs will be the same.\n",
    "test_array=np.arange(10)\n",
    "print 'Output of the accor function:  '+ str(acorr(test_array))\n",
    "print 'Output of the correlate function:  '+str(np.correlate(test_array,test_array,\"full\")[len(test_array)-1:2*len(test_array)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (2 points) Implement the beat spectrum. Use the autocorrelation function from Question 3. Do not square the magnitude spectrogram within your function; it will be squared outside the function, in the *repet* function. Apply the function to the spectrogram of the noisy as well as the denoised signals. Plot both beat spectra. Do you observe any noticeable difference between the plots? What information does the beat spectrum provide regarding the ringing noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def beat_spectrum(S):\n",
    "    \"\"\"\n",
    "    Computes the beat spectrum of a music mixture by applyting the autocorrelation to all frequency channels (rows)\n",
    "    of the spectrogram and taking the average. Note that the assumption is that the mixture is composed of a repeating\n",
    "    background and a non-repeating foreground. Therefore, the spikes in the beat spectrum represent the repetitive \n",
    "    events in the spectrogram.  This function must PLOT the beat spectrum for viewing, since you'll be looking at the\n",
    "    resulting plot to pick the repeating period used by REPET. \n",
    "    \n",
    "    Input Parameter:\n",
    "    ----------------\n",
    "    S: 2D numpy array containng the spectrogram of a signal\n",
    "    \n",
    "    Output Parameter:\n",
    "    ------------------\n",
    "    beat_spec: 1D numpy array containing the beat spectrum \n",
    "    \n",
    "    \"\"\"\n",
    "    # your code goes here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. (1 point) Explain how you would find the period of the repeating structure from the beat spectrum. Remember that the repeating period does not necessarily correspond to the first highest peak. Remember also that the beat spectrum goes from lag 0 to lag n-1, where n is the length of the input signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPET Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. (2 point) Implement a repeating-segment modeling function (Hint: use the numpy *median* function). Note that after segmentation of the spectrogram, the last segment is generally shorter (in time frames) than the other segments, because the number of time frames is not necessarily an integer multiple of the repeating period; Think about how you would handle that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeating_segment(V,p):\n",
    "    \"\"\"\n",
    "    Computes the repeating-segment model using the period obtained from the beat spectrum. The repeating segment\n",
    "    is that median background we'll be using to compare to the spectrum. Its time duration will be the length of\n",
    "    one period that you learned from the beat spectrum. \n",
    "    \n",
    "    Input Parameters:\n",
    "    -----------------\n",
    "    V: 2D numpy array containing the magnitude spectrogram of the mixture\n",
    "    p: scalar, repeating period (in number of samples) found from the beat spectrum \n",
    "    \n",
    "    Output Parameter:\n",
    "    S: 2D numpy array containing the repeating segment \n",
    "    \"\"\"  \n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. (2 point) Implement a repeating spectrogram modeling function (Hint: use the min function). Again, the last segment in your spectrogram is generally shorter than the repeating segment model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeating_spectrogram(V,S):\n",
    "    \"\"\"\n",
    "    Builds the repeating-spectrogram model using the repeating segment model computed in the previous question.\n",
    "    This is composed of multiple copies of the repeating segment, tiled together in the time-dimension so that it\n",
    "    is the exact same size as the input signal's spectrogram.\n",
    "    \n",
    "    Input Parameters:\n",
    "    -----------------\n",
    "    V: 2D numpy array containing the magnitude spectrogram of the mixture\n",
    "    S: 2D numpy array containing the repeating segment model \n",
    "    \n",
    "    Output Parameter:\n",
    "    ------------------\n",
    "    W: 2D numpy array containing the repeating-spectrogram \n",
    "    \"\"\"\n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. (1 point) Implement a repeating-mask modeling function (Hint: use a division). Note that there could be zero values in your spectrogram. Think about how to handle that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeating_mask(V,W):\n",
    "    \"\"\"\n",
    "    Before we do our separation, we need to compare our repeating_spectrogram to the original spectrogram of the signal\n",
    "    to determine how to assign the energy in each time-frequency point (each element in your matrix). This function\n",
    "    does that and makes a mask that will be applied to the spectrum. Note that unlike the denoising case in the first \n",
    "    question, here we are computing a \"soft mask\" with values ranging between 0 and 1.\n",
    "    \n",
    "    Input Parameters:\n",
    "    -----------------\n",
    "    V: numpy 2D array containing the magnitude spectrogram \n",
    "    W: numpy 2D array containing the repeating spectrogram\n",
    "    \n",
    "    Output Parameter:\n",
    "    M: numpy 2D array containing the repeating mask \n",
    "    \"\"\"\n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music-voice Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.  (2 points) The function provided below runs the REPET algorithm using functions you wrote in previous questions. REPET builds a soft time-frequency mask (with values between 0 and 1), but we can also derive a binary time-frequency mask from it (with values of only 0s and 1s). To do so, we simply use a threshold value between 0 and 1 in the soft mask, so that values above the threshold will be forced to 1, while values below the threshold will be forced to 0. A binary mask can help to improve the perception of separation, but it will also increase the separation artifacts. \n",
    "\n",
    "#### Select the value of the repeating period in samples and the value of the masking threshold. Try different values of the masking threshold and compute the background and foreground audio estimates. Listen to the estimate and plot the magnitude spectrograms of the background and foreground estimates for each masking threshold you try. Write down the value of the masking threshold that gave you the best separation results.\n",
    "\n",
    "#### Describe the separation results that you have obtained. Are the repeating musical background and the non-repeating vocal foreground well separated? Did you get any kind of audio artifacts? What did happen to the ringing noise? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repet(file_path, rep_period, mask_thr):\n",
    "    \"\"\"\n",
    "    Runs the REPET algorithm using functions implemented in qustions 3 through 8. NOTE: In the real REPET algorithm\n",
    "    it also determines the repeating period from the beat spectrum by building a peak picker to find the best\n",
    "    period from the beat spectrum. This seemed like too much for a homework, so we're making YOU the peak picker. \n",
    "    You'll have to run the beat_spectrum function before calling repet and input the value for rep_period.\n",
    "    \n",
    "    Input Parameters:\n",
    "    ------------------\n",
    "    file_path: string, path to the audio file to separate\n",
    "    rep_period: scalar, repeating period in number of samples\n",
    "    mask_thr: scalar, a value between 0 and 1 for thresholding the soft mask\n",
    "    \n",
    "    Output:\n",
    "    --------\n",
    "    Separated background and foreground magnitude spectrogram plots \n",
    "    \n",
    "    Returns: \n",
    "    ---------\n",
    "    Separated background and foreground time signals\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the noisy mixture\n",
    "    signal, sample_rate = librosa.load(file_path, 44100) \n",
    "\n",
    "    # Comput the stft of the audio signal \n",
    "    win_length_sec=0.04 # 40 msec window\n",
    "    win_length_samp=int(2**np.ceil(np.log2(win_length_sec*sample_rate))) # next power2 of winow length in no. of samples\n",
    "    n_fft=win_length_samp\n",
    "    hop_size=win_length_samp/2 # 50% overlap\n",
    "    win_type=sp.signal.hanning\n",
    "    X = stft(signal, win_length_samp, hop_size, window_type = 'hann')\n",
    "\n",
    "    # Compute the magnitude spectrogram (half spectrum)\n",
    "    Vm = np.abs(X[0:win_length_samp/2+1,:])\n",
    "    Nf,Nt=Vm.shape\n",
    "    \n",
    "    \n",
    "    # Compute and plot the beat spectrum\n",
    "    beat_spec = beat_spectrum(Vm**2)\n",
    "    beat_spec = beat_spec/beat_spec[0] # normalization\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(beat_spec)\n",
    "    plt.grid('on')\n",
    "    plt.axis('tight')\n",
    "    plt.xlabel('Lag (sample number)')\n",
    "    plt.title('Beat spectrum of the noisy mixture')\n",
    "    \n",
    "    ### REPET Algorithm ###\n",
    "    \n",
    "    # Compute the repeating soft mask\n",
    "    Sm=repeating_segment(Vm,rep_period)\n",
    "    Wm=repeating_spectrogram(Vm,Sm)\n",
    "    soft_mask=repeating_mask(Vm,Wm)\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.pcolormesh(soft_mask)\n",
    "    \n",
    "    # Compute the repeating binary mask\n",
    "    binary_mask=np.zeros(soft_mask.shape)\n",
    "    binary_mask[soft_mask>=mask_thr]=1\n",
    "    \n",
    "    \n",
    "    # Estimate the background and foreground via masking\n",
    "    binary_mask=np.vstack([binary_mask,np.flipud(binary_mask[1:-1,:])])\n",
    "    \n",
    "    X_bg = binary_mask*X+1e-16  # background STFT\n",
    "    signal_bg = np.real(istft(X_bg, hop_size)) # background time signal\n",
    "    \n",
    "    X_fg = (1-binary_mask)*X+1e-16  # foreground STFT\n",
    "    signal_fg = np.real(istft(X_fg, hop_size)) # foreground time signal\n",
    "            \n",
    "    # Plot the log magnitude spectrograms and the binary mask\n",
    "    plt.figure()    \n",
    "    plt.subplot(211)\n",
    "    plt_spectrogram(X,win_length_samp, hop_size, sample_rate,tick_labels='time-freq')\n",
    "    plt.title('Mixture')\n",
    "        \n",
    "    plt.subplot(212)\n",
    "    plt.pcolormesh(binary_mask[0:Nf,:])\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title('Binary mask')\n",
    "    plt.axis('tight')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt_spectrogram(X_bg,win_length_samp, hop_size, sample_rate,tick_labels='time-freq')\n",
    "    plt.title('Background')\n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt_spectrogram(X_fg,win_length_samp, hop_size, sample_rate,tick_labels='time-freq')\n",
    "    plt.title('Foreground')\n",
    "    \n",
    "    return signal_bg,signal_fg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answers go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. (2 points) Go out on the web and find an example of music where REPET works well to separate out the voice and an example where it works poorly and do the following:\n",
    "1. Crop each example to be between 10 and 30 seconds (pick a length appropriate for making your point)\n",
    "1. Save each cropped example at the sample rate 22050 Hz\n",
    "1. Make each example monophonic (ie one channel, not two)\n",
    "1. Include both examples with your submission\n",
    "1. Write the code to call repet, separate the sources and play them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
